EventId,EventTemplate,Occurrences
0,Created MRAppMaster for application <*>,1
1,Executing with tokens:,1
2,"Kind: YARN_AM_RM_TOKEN, Service: , Ident: (<*>)",1
3,Using mapred newApiCommitter.,1
4,OutputCommitter set in config <*>,1
5,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,1
6,Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,1
7,Registering class org.apache.hadoop.mapreduce.v2.app.<*>.<*> for class org.apache.hadoop.mapreduce.v2.app.<*>,8
8,Default file system [<*>],3
9,Emitting job history data to the timeline server is not enabled,1
10,loaded properties from hadoop-metrics2.properties,1
11,Scheduled snapshot period at <*> second(s).,1
12,MRAppMaster metrics system started,1
13,Adding job token for <*> to jobTokenSecretManager,1
14,Not uberizing <*> because: not enabled; too many maps; too much input;,1
15,Input size for job <*> = <*> Number of splits = <*>,1
16,Number of reduces for job <*> = <*>,1
17,job_<*>Job Transitioned from NEW to INITED,1
18,"MRAppMaster launching normal, non-uberized, multi-container job <*>",1
19,Using callQueue class java.util.concurrent.LinkedBlockingQueue,2
20,Starting Socket Reader <*> for port <*>,2
21,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,1
22,Instantiated MRClientService at <*>,1
23,IPC Server Responder: starting,2
24,IPC Server listener on <*>: starting,2
25,Logging to <*>(org.mortbay.log) via <*>,1
26,Http request log for http.requests.mapreduce is not defined,1
27,Added global filter '<*>(class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),1
28,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce,1
29,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static,1
30,adding path spec: <*>,2
31,Jetty bound to port <*>,1
32,jetty-<*>,1
33,Extract jar:file:<*> to <*>,1
34,Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>,1
35,Web app <*> started at <*>,1
36,Registered webapp guice modules,1
37,JOB_CREATE <*>,1
38,nodeBlacklistingEnabled:<*>,1
39,maxTaskFailuresPerNode is <*>,1
40,blacklistDisablePercent is <*>,1
41,Connecting to ResourceManager at <*>:<*>,1
42,maxContainerCapability: <*>,1
43,queue: default,1
44,Upper limit on the thread pool size is <*>,1
45,yarn.client.max-cached-nodemanagers-proxies : <*>,1
46,job_<*>Job Transitioned from INITED to SETUP,1
47,Processing the event EventType: JOB_SETUP,1
48,job_<*>Job Transitioned from SETUP to RUNNING,1
49,Resolved <*> to <*>,39
50,task_<*> Task Transitioned from NEW to SCHEDULED,11
51,attempt_<*>_<*>_<*> TaskAttempt Transitioned from NEW to UNASSIGNED,14
52,"mapResourceRequest:<memory:<*>, vCores:<*>>",1
53,Event Writer setup for JobId: <*> File: <*>,1
54,"reduceResourceRequest:<memory:<*>, vCores:<*>>",1
55,<*> Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,17
56,"getResources() for application_<*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*>> knownNMs=<*>",12
57,"Recalculating schedule, headroom=<memory:<*>, vCores:<*>>",131
58,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>,130
59,Got allocated containers <*>,10
60,Assigned container <*> to attempt<*>,10
61,The job-jar file on the remote FS is <*>,1
62,The job-conf file on the remote FS is <*>,1
63,Adding <*> tokens and <*> secret keys for NM use for launching container,1
64,Size of containertokens_dob is <*>,1
65,Putting shuffle token in serviceData,1
66,attempt_<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED,10
67,Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>,10
68,Launching <*>,10
69,Opening proxy : <*>,13
70,Shuffle port returned by ContainerManager for <*> : <*>,10
71,TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>],10
72,attempt_<*> TaskAttempt Transitioned from ASSIGNED to RUNNING,10
73,ATTEMPT_START task_<*>,10
74,task_<*> Task Transitioned from SCHEDULED to RUNNING,10
75,Auth successful for <*> (auth:SIMPLE),10
76,JVM with ID : <*> asked for a task,10
77,JVM with ID: <*> given task: <*>,10
78,Progress of TaskAttempt <*> is : <*>,289
79,"Cannot assign container Container: [ContainerId: <*>, NodeId: <*>, NodeHttpAddress: <*>, Resource: <*> vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*> }, ] for a map as either container memory less than required <*> or no pending map tasks - maps.isEmpty=<*>",1
80,Received completed container <*>,2
81,Container complete event for unknown container id <*>,1
82,Done acknowledgement from <*>,1
83,attempt_<*> TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP,1
84,Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>,3
85,KILLING <*>,3
86,attempt_<*> TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED,1
87,Task succeeded with attempt <*>,1
88,task_<*> Task Transitioned from RUNNING to SUCCEEDED,1
89,Num completed Tasks: <*>,1
90,Reduce slow start threshold reached. Scheduling reduces.,1
91,All maps assigned. Ramping up all remaining reduces:<*>,1
92,DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>,1
93,We launched <*> speculations. Sleeping <*> milliseconds.,1
94,Scheduling a redundant attempt for task <*>,1
95,Diagnostics report from <*>: Container killed by the ApplicationMaster.,1
96,Address change detected. Old: <*> New: <*>:<*>,476
97,Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...,326
98,Slow ReadProcessor read fields took <*>ms (threshold=<*>ms); ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*> targets: [<*>:<*>],1
99,DFSOutputStream ResponseProcessor exception for block <*>:<*>,1
100,"Error Recovery for block <*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>",1
101,DataStreamer Exception,1
102,ERROR IN CONTACTING RM.,147
103,"Retrying connect to server: <*>. Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)",146
104,Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from <*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost,2
105,Diagnostics report from <*>: Error: java.net.NoRouteToHostException: No Route to Host from <*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost,4
106,attempt_<*> TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP,2
107,attempt_<*> TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP,2
108,Processing the event EventType: TASK_ABORT,2
109,Task cleanup failed for attempt <*>,2
110,attempt_<*> TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED,2
111,Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@<*>,1
112,"Thread Thread[eventHandlingThread,<*>,main] threw an Exception.",1
113,<*> failures on node <*>,2
114,Added <*> to list of failed maps,2
